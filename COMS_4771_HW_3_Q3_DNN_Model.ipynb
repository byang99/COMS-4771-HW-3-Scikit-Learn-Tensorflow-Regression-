{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "COMS 4771 HW 3 Q3 - DNN Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5UWISmOaUwO"
      },
      "source": [
        "import scipy.io\n",
        "import math\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPool2D, ZeroPadding2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.modeling\n",
        "import tensorflow_docs.plots\n",
        "\n",
        "from sklearn.linear_model import Ridge, Lasso, LogisticRegression, LinearRegression, SGDRegressor, ElasticNet\n",
        "import sklearn.neighbors as neighbors\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, PowerTransformer, QuantileTransformer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from  IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import pathlib\n",
        "import shutil\n",
        "import tempfile\n",
        "\n",
        "np.set_printoptions(precision=3, suppress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1FWut6uwSA1"
      },
      "source": [
        "# !pip install git+https://github.com/tensorflow/docs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "Ca437QSeqxmL",
        "outputId": "a8033296-c6ed-46ef-c064-6c66c56ccbe8"
      },
      "source": [
        "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
        "shutil.rmtree(logdir, ignore_errors=True)\n",
        "N_VALIDATION = int(1e3)\n",
        "N_TRAIN = int(1e4)\n",
        "BUFFER_SIZE = int(1e4)\n",
        "BATCH_SIZE = 500\n",
        "# STEPS_PER_EPOCH = N_TRAIN//BATCH_SIZE\n",
        "STEPS_PER_EPOCH = 10000\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "  0.001,\n",
        "  decay_steps=STEPS_PER_EPOCH*1000,\n",
        "  decay_rate=1,\n",
        "  staircase=False)\n",
        "\n",
        "def get_optimizer():\n",
        "  return tf.keras.optimizers.Adam(lr_schedule)\n",
        "\n",
        "\n",
        "step = np.linspace(0,100000)\n",
        "lr = lr_schedule(step)\n",
        "plt.figure(figsize = (8,6))\n",
        "plt.plot(step/STEPS_PER_EPOCH, lr)\n",
        "plt.ylim([0,max(plt.ylim())])\n",
        "plt.xlabel('Epoch')\n",
        "_ = plt.ylabel('Learning Rate')\n",
        "\n",
        "\n",
        "def get_callbacks(name):\n",
        "  checkpoint_filepath = '/content/dnn_model'\n",
        "  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_mean_absolute_error',\n",
        "    mode='min',\n",
        "    save_best_only=True)\n",
        "  \n",
        "  return [\n",
        "    tfdocs.modeling.EpochDots(),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='mean_absolute_error', patience=200),\n",
        "    tf.keras.callbacks.TensorBoard(logdir/name),\n",
        "    model_checkpoint_callback\n",
        "  ]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAAF3CAYAAADaXFNkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAapUlEQVR4nO3df5TldX3f8edrZwUR44q4QWWJu5HFPYvBWCdEjadNxBzWmrppQ+MSm0MrhtMUjBpPE+gxx4Zjz5GmhdQU0qyyhlJ04aCpk8SKFlKNqQUGtYbFbJyAyiLK8kMEq8DOvPvH/Q579+6dmbvsfO9l7j4f58y53+/n8/l+vu/vd1n2Nd/7vd+bqkKSJB3ZVo26AEmSNHoGAkmSZCCQJEkGAkmShIFAkiRhIJAkSbQcCJJsSbI7yUySC/v0H53k2qb/5iTru/ouatp3Jzmzq31HkvuS3N4z1/OSfCbJ15rX49o8NkmSxklrgSDJBHA58AZgM3B2ks09w84FHqqqk4HLgEuabTcD24BTgS3AFc18AH/ctPW6ELixqjYCNzbrkiRpAG1eITgdmKmqO6vqcWAnsLVnzFbgqmb5euCMJGnad1bVY1V1FzDTzEdVfQ54sM/+uue6CvjF5TwYSZLGWZuB4ETg7q71PU1b3zFVtQ94GDh+wG17nVBV9zbL3wZOeGplS5J05Fk96gLaUFWVpO8zmZOcB5wHcOyxx75y06ZNy7LP7/6/J/jBE7MUBc2euwvofkL00mOq015L9B80L13z1kHbdW1+YH+/fS1Q45EuXQvZv9ZZSlc/TX/6bdfV32+7A7bJAW2L1tA75sl50qete385sO0Qj6N7zP5j693XUsexyJje/j5zL3xsB1R40JiD+vscmzRObrvttvuram2/vjYDwT3ASV3r65q2fmP2JFkNrAEeGHDbXt9J8sKqujfJC4H7+g2qqu3AdoDJycmanp4e8HBUVVTBbPM6V9X8dJZrrvM6319dfXNd28zOdeLIAf1z+8cd1D/Xee0eP1udwHLA/rv757prPLh/rtnH/NxzdfD4+TGdubqPpVPLfJ0HbtvTX3TVXsx21dKvv7eWvueqe765/X8uved5rjq1w8G1dR/jXJ/au+sY6L+NntdxkcCqhFXpBKdVT643y6uyYH/3tgeudy2vmu/r3naQubr6V82P77RNLNg/4Hw5cL5Vqw5x/CLHt3Bt/c/Toudi1QD7X2iOVQf/2Ux0zT8fksdRkm8s1NdmILgV2JhkA51/zLcBv9IzZgo4B/gCcBZwU/Pb/RTwkSSXAi8CNgK3LLG/+bne37x+YrkORB2Z/4vm709HjFogJBwQBruCUW+4qyaU7A9OB4fA/SFz4cAy31/N1a39+2jCV1ddCwXBhYLdQeFp7uBte0Po7Fyf4+m77z4hc4H99w90cwfU2znXB567A85115/BwiFyPmT2D4Lz5+FItlgQzHx/nzD4ZOBZdajha+HA88oXH8c7X3/KUI67tUBQVfuSXADcAEwAO6pqV5KLgemqmgKuBK5OMkPnRsFtzba7klwH3AHsA86vqlmAJB8FfhZ4fpI9wHur6ko6QeC6JOcC3wB+ua1jk44USZjovtauI0ItEm6WugL4ZHDpCigLBcHFrlztD5ld4Wuud38Lh7HeOappm13oCl9PEJzt2ke/K3i9Yzrb94SvOvgKXm/42n8FcP/xzc4VT8x22n7wxOzQ/txzJH/9sW8ZSJKOJEluq6rJfn0+qVCSJBkIJEmSgUCSJGEgkCRJGAgkSRIGAkmShIFAkiRhIJAkSRgIJEkSBgJJkoSBQJIkYSCQJEkYCCRJEgYCSZKEgUCSJGEgkCRJGAgkSRIGAkmShIFAkiRhIJAkSRgIJEkSBgJJkoSBQJIkYSCQJEkYCCRJEgYCSZKEgUCSJGEgkCRJGAgkSRIGAkmShIFAkiRhIJAkSRgIJEkSBgJJkoSBQJIkYSCQJEkYCCRJEgYCSZKEgUCSJGEgkCRJGAgkSRIGAkmShIFAkiRhIJAkSRgIJEkSBgJJkoSBQJIkYSCQJEkYCCRJEgYCSZKEgUCSJGEgkCRJGAgkSRIGAkmShIFAkiRhIJAkSbQcCJJsSbI7yUySC/v0H53k2qb/5iTru/ouatp3JzlzqTmTnJHki0m+nOTzSU5u89gkSRonrQWCJBPA5cAbgM3A2Uk29ww7F3ioqk4GLgMuabbdDGwDTgW2AFckmVhizj8E3lJVPwl8BHhPW8cmSdK4afMKwenATFXdWVWPAzuBrT1jtgJXNcvXA2ckSdO+s6oeq6q7gJlmvsXmLOA5zfIa4FstHZckSWNndYtznwjc3bW+B/jphcZU1b4kDwPHN+3/p2fbE5vlheZ8G/DJJD8Avge8ahmOQZKkI8I43VT4LuAfVtU64MPApf0GJTkvyXSS6b179w61QEmSnq7aDAT3ACd1ra9r2vqOSbKazqX+BxbZtm97krXAy6vq5qb9WuA1/Yqqqu1VNVlVk2vXrn0qxyVJ0thpMxDcCmxMsiHJUXRuEpzqGTMFnNMsnwXcVFXVtG9rPoWwAdgI3LLInA8Ba5Kc0sz188BXWzw2SZLGSmv3EDT3BFwA3ABMADuqaleSi4HpqpoCrgSuTjIDPEjnH3iacdcBdwD7gPOrahag35xN+68BH0syRycgvLWtY5Mkadyk8wv5kWlycrKmp6dHXYYkSUOR5LaqmuzXN043FUqSpKfIQCBJkgwEkiTJQCBJkjAQSJIkDASSJAkDgSRJwkAgSZIwEEiSJAwEkiQJA4EkScJAIEmSMBBIkiQMBJIkCQOBJEnCQCBJkjAQSJIkDASSJAkDgSRJwkAgSZIwEEiSJAwEkiQJA4EkScJAIEmSMBBIkiQMBJIkCQOBJEnCQCBJkjAQSJIkDASSJAkDgSRJwkAgSZIwEEiSJAwEkiQJA4EkScJAIEmSMBBIkiQMBJIkCQOBJEnCQCBJkjAQSJIkDASSJAkDgSRJwkAgSZIwEEiSJAwEkiQJA4EkScJAIEmSMBBIkiQMBJIkCQOBJEnCQCBJkjAQSJIkDASSJAkDgSRJwkAgSZIwEEiSJFoOBEm2JNmdZCbJhX36j05ybdN/c5L1XX0XNe27k5y51Jzp+HdJ/jbJV5P8RpvHJknSOFnd1sRJJoDLgZ8H9gC3Jpmqqju6hp0LPFRVJyfZBlwCvDnJZmAbcCrwIuB/Jjml2WahOf85cBKwqarmkvxoW8cmSdK4afMKwenATFXdWVWPAzuBrT1jtgJXNcvXA2ckSdO+s6oeq6q7gJlmvsXm/HXg4qqaA6iq+1o8NkmSxsqSgSDJKUluTHJ7s35akvcMMPeJwN1d63uatr5jqmof8DBw/CLbLjbnS+hcXZhO8j+SbFzgeM5rxkzv3bt3gMOQJGn8DXKF4IPARcATAFX1FTqX859ujgZ+WFWTdGre0W9QVW2vqsmqmly7du1QC5Qk6elqkEDwrKq6padt3wDb3UPnPf1565q2vmOSrAbWAA8ssu1ic+4BPt4s/wlw2gA1SpIkBgsE9yd5CVAASc4C7h1gu1uBjUk2JDmKzlWFqZ4xU8A5zfJZwE1VVU37tuZTCBuAjcAtS8z534Gfa5b/AfC3A9QoSZIY7FMG5wPbgU1J7gHuAt6y1EZVtS/JBcANwASwo6p2JbkYmK6qKeBK4OokM8CDNG9FNOOuA+6gczXi/KqaBeg3Z7PL9wPXJHkX8CjwtoHOgCRJIp1fyBcZkGyoqruSHAusqqpH5tuGU2J7Jicna3p6etRlSJI0FElua+61O8ggbxl8DKCqvl9VjzRt1y9XcZIkafQWfMsgySY6DwZak+SfdHU9B3hm24VJkqThWewegpcCvwA8F/hHXe2PAL/WZlGSJGm4FgwEVfUJ4BNJXl1VXxhiTZIkacgG+ZTBl5KcT+ftgyffKqiqt7ZWlSRJGqpBbiq8GngBcCbwWToPA3pk0S0kSdKKMkggOLmqfgf4flVdBbwR+Ol2y5IkScM0SCB4onn9bpKX0Xm8sF8tLEnSGBnkHoLtSY4D3kPnMcHPBn6n1aokSdJQLRkIqupDzeLngB8HSPJjbRYlSZKGa9G3DJK8OslZSX60WT8tyUeAvxpKdZIkaSgWDARJfg/YAfwS8OdJ3gd8GriZzrcPSpKkMbHYWwZvBF5RVT9s7iG4G3hZVX19KJVJkqShWewtgx9W1Q8Bquoh4GuGAUmSxtNiVwh+PMlU1/qG7vWqelN7ZUmSpGFaLBBs7Vn/j20WIkmSRmexLzf67DALkSRJozPIkwolSdKYMxBIkiQDgSRJGuDRxUn+FKie5oeBaeCP5j+aKEmSVq5BrhDcCTwKfLD5+R7wCHBKsy5Jkla4Qb7t8DVV9VNd63+a5Naq+qkku9oqTJIkDc8gVwie3f3ths3ys5vVx1upSpIkDdUgVwjeDXw+yd8BATYA/yrJscBVbRYnSZKGY8lAUFWfTLIR2NQ07e66kfD3W6tMkiQNzSBXCABeCaxvxr88CVX1X1urSpIkDdUgHzu8GngJ8GVgtmkuwEAgSdKYGOQKwSSwuap6n0UgSZLGxCCfMrgdeEHbhUiSpNEZ5ArB84E7ktwCPDbfWFVvaq0qSZI0VIMEgn/bdhGSJGm0BvnY4WeHUYgkSRqdBQNBks9X1WuTPMKBX24UoKrqOa1XJ0mShmLBQFBVr21ef2R45UiSpFEY6MFESSaAE7rHV9U32ypKkiQN1yAPJno78F7gO8Bc01zAaS3WJUmShmiQKwTvAF5aVQ+0XYwkSRqNQR5MdDfwcNuFSJKk0RnkCsGdwP9K8ucc+GCiS1urSpIkDdUggeCbzc9RzY8kSRoziwaC5tMFp1TVW4ZUjyRJGoFF7yGoqlngxUm8MiBJ0hgb9B6Cv0oyBXx/vtF7CCRJGh+DBIK/a35WAT61UJKkMTTIlxv97jAKkSRJozPIkwrXAr8FnAo8c769ql7XYl2SJGmIBnkw0TXA3wAbgN8Fvg7c2mJNkiRpyAYJBMdX1ZXAE1X12ap6K+DVAUmSxsggNxU+0bzem+SNwLeA57VXkiRJGrZBAsH7kqwB3g38AfAc4F2tViVJkoZqkE8Z/Fmz+DDwc+2WI0mSRmHJewiSnJLkxiS3N+unJXlP+6VJkqRhGeSmwg8CF9HcS1BVXwG2tVmUJEkarkECwbOq6paetn1tFCNJkkZjkEBwf5KXAAWQ5Czg3larkiRJQzVIIDgf+CNgU5J7gHcC/3KQyZNsSbI7yUySC/v0H53k2qb/5iTru/ouatp3JznzEOb8QJJHB6lPkiR1LBkIqurOqno9sBbYVFWvBf7xUtslmQAuB94AbAbOTrK5Z9i5wENVdTJwGXBJs+1mOvcpnApsAa5IMrHUnEkmgeOWqk2SJB1okCsEAFTV96vqkWb1NwfY5HRgpgkUjwM7ga09Y7YCVzXL1wNnJEnTvrOqHququ4CZZr4F52zCwu/R+d4FSZJ0CAYOBD0ywJgTgbu71vc0bX3HVNU+Os86OH6RbReb8wJgqqoWvb8hyXlJppNM7927d4DDkCRp/D3VQFDLWsVhSvIi4J/SeZLioqpqe1VNVtXk2rVr2y9OkqQVYMEnFSZ5hP7/8Ac4ZoC57wFO6lpf17T1G7MnyWpgDfDAEtv2a38FcDIw03nHgWclmWnuTZAkSUtYMBBU1Y8c5ty3AhuTbKDzj/Y24Fd6xkwB5wBfAM4CbqqqSjIFfCTJpcCLgI3ALXTCyEFzVtUu4AXzkyZ51DAgSdLgBvlyo6ekqvYluQC4AZgAdlTVriQXA9NVNQVcCVydZAZ4kOYJiM2464A76DwE6fyqmgXoN2dbxyBJ0pEiVU+r2wGGanJysqanp0ddhiRJQ5Hktqqa7Nf3VG8qlCRJY8RAIEmSDASSJMlAIEmSMBBIkiQMBJIkCQOBJEnCQCBJkjAQSJIkDASSJAkDgSRJwkAgSZIwEEiSJAwEkiQJA4EkScJAIEmSMBBIkiQMBJIkCQOBJEnCQCBJkjAQSJIkDASSJAkDgSRJwkAgSZIwEEiSJAwEkiQJA4EkScJAIEmSMBBIkiQMBJIkCQOBJEnCQCBJkjAQSJIkDASSJAkDgSRJwkAgSZIwEEiSJAwEkiQJA4EkScJAIEmSMBBIkiQMBJIkCQOBJEnCQCBJkjAQSJIkDASSJAkDgSRJwkAgSZIwEEiSJAwEkiQJA4EkScJAIEmSMBBIkiQMBJIkCQOBJEnCQCBJkmg5ECTZkmR3kpkkF/bpPzrJtU3/zUnWd/Vd1LTvTnLmUnMmuaZpvz3JjiTPaPPYJEkaJ60FgiQTwOXAG4DNwNlJNvcMOxd4qKpOBi4DLmm23QxsA04FtgBXJJlYYs5rgE3ATwDHAG9r69gkSRo3bV4hOB2Yqao7q+pxYCewtWfMVuCqZvl64Iwkadp3VtVjVXUXMNPMt+CcVfXJagC3AOtaPDZJksZKm4HgRODurvU9TVvfMVW1D3gYOH6RbZecs3mr4FeBTx32EUiSdIQYx5sKrwA+V1V/2a8zyXlJppNM7927d8ilSZL09NRmILgHOKlrfV3T1ndMktXAGuCBRbZddM4k7wXWAr+5UFFVtb2qJqtqcu3atYd4SJIkjac2A8GtwMYkG5IcRecmwameMVPAOc3yWcBNzT0AU8C25lMIG4CNdO4LWHDOJG8DzgTOrqq5Fo9LkqSxs7qtiatqX5ILgBuACWBHVe1KcjEwXVVTwJXA1UlmgAfp/ANPM+464A5gH3B+Vc0C9Juz2eV/Ab4BfKFzXyIfr6qL2zo+SZLGSTq/kB+ZJicna3p6etRlSJI0FEluq6rJfn3jeFOhJEk6RAYCSZJkIJAkSQYCSZKEgUCSJGEgkCRJGAgkSRIGAkmShIFAkiRhIJAkSRgIJEkSBgJJkoSBQJIkYSCQJEkYCCRJEgYCSZKEgUCSJGEgkCRJGAgkSRIGAkmShIFAkiRhIJAkSRgIJEkSBgJJkoSBQJIkYSCQJEkYCCRJEgYCSZKEgUCSJGEgkCRJGAgkSRIGAkmShIFAkiRhIJAkSRgIJEkSBgJJkoSBQJIkYSCQJEkYCCRJEgYCSZKEgUCSJGEgkCRJGAgkSRIGAkmShIFAkiRhIJAkSRgIJEkSBgJJkoSBQJIkYSCQJEkYCCRJEgYCSZKEgUCSJGEgkCRJGAgkSRIGAkmSRMuBIMmWJLuTzCS5sE//0UmubfpvTrK+q++ipn13kjOXmjPJhmaOmWbOo9o8NkmSxklrgSDJBHA58AZgM3B2ks09w84FHqqqk4HLgEuabTcD24BTgS3AFUkmlpjzEuCyZq6HmrklSdIA2rxCcDowU1V3VtXjwE5ga8+YrcBVzfL1wBlJ0rTvrKrHquouYKaZr++czTava+agmfMXWzw2SZLGSpuB4ETg7q71PU1b3zFVtQ94GDh+kW0Xaj8e+G4zx0L7kiRJC1g96gKGLcl5wHnN6qNJdi/j9M8H7l/G+Y5EnsPD5zlcHp7Hw+c5PHzLfQ5fvFBHm4HgHuCkrvV1TVu/MXuSrAbWAA8ssW2/9geA5yZZ3Vwl6LcvAKpqO7D9qRzQUpJMV9VkG3MfKTyHh89zuDw8j4fPc3j4hnkO23zL4FZgY3P3/1F0bhKc6hkzBZzTLJ8F3FRV1bRvaz6FsAHYCNyy0JzNNn/RzEEz5ydaPDZJksZKa1cIqmpfkguAG4AJYEdV7UpyMTBdVVPAlcDVSWaAB+n8A08z7jrgDmAfcH5VzQL0m7PZ5W8DO5O8D/hSM7ckSRpAOr9cazkkOa95S0JPkefw8HkOl4fn8fB5Dg/fMM+hgUCSJPnoYkmSZCBYNks9plmLS3JSkr9IckeSXUneMeqaVqrmqZ5fSvJno65lJUry3CTXJ/mbJF9N8upR17TSJHlX8/f49iQfTfLMUde0EiTZkeS+JLd3tT0vyWeSfK15Pa6t/RsIlsGAj2nW4vYB766qzcCrgPM9h0/ZO4CvjrqIFew/AZ+qqk3Ay/FcHpIkJwK/AUxW1cvo3AC+bbRVrRh/TOdx/d0uBG6sqo3Ajc16KwwEy2OQxzRrEVV1b1V9sVl+hM7/hH3a5CFKsg54I/ChUdeyEiVZA/x9mk8pVdXjVfXd0Va1Iq0GjmmeL/Ms4FsjrmdFqKrP0fnEXbfuR/y3+lh+A8HyGOQxzRpQ862XrwBuHm0lK9LvA78FzI26kBVqA7AX+HDztsuHkhw76qJWkqq6B/gPwDeBe4GHq+rTo61qRTuhqu5tlr8NnNDWjgwEelpJ8mzgY8A7q+p7o65nJUnyC8B9VXXbqGtZwVYDfw/4w6p6BfB9WrxEO46a97i30glXLwKOTfLPRlvVeGgewtfaRwMNBMtjkMc0awlJnkEnDFxTVR8fdT0r0M8Ab0rydTpvW70uyX8bbUkrzh5gT1XNX526nk5A0OBeD9xVVXur6gng48BrRlzTSvadJC8EaF7va2tHBoLlMchjmrWI5iusrwS+WlWXjrqelaiqLqqqdVW1ns5/gzdVlb+ZHYKq+jZwd5KXNk1n0Hliqgb3TeBVSZ7V/L0+A2/MPBzdj/hv9bH8R9y3HbZhocc0j7isleZngF8F/jrJl5u2f1NVnxxhTToyvR24pgn3dwL/YsT1rChVdXOS64Ev0vn00Jdo6Qvlxk2SjwI/Czw/yR7gvcD7geuSnAt8A/jl1vbvkwolSZJvGUiSJAOBJEkyEEiSJAwEkiQJA4EkScJAIOkwJJlN8uWun2V7ql+S9d3f+iapXT6HQNLh+EFV/eSoi5B0+LxCIGnZJfl6kn+f5K+T3JLk5KZ9fZKbknwlyY1JfqxpPyHJnyT5v83P/KNuJ5J8MMmuJJ9OcszIDkoacwYCSYfjmJ63DN7c1fdwVf0E8J/pfAsjwB8AV1XVacA1wAea9g8An62ql9P57oD5J31uBC6vqlOB7wK/1PLxSEcsn1Qo6SlL8mhVPbtP+9eB11XVnc2XVn27qo5Pcj/wwqp6omm/t6qen2QvsK6qHuuaYz3wmara2Kz/NvCMqnpf+0cmHXm8QiCpLbXA8qF4rGt5Fu97klpjIJDUljd3vX6hWf7fdL6JEeAtwF82yzcCvw6QZCLJmmEVKanDtC3pcBzT9e2UAJ+qqvmPHh6X5Ct0fss/u2l7O/DhJP8a2Mv+bxJ8B7C9+Ua3WTrh4N7Wq5f0JO8hkLTsmnsIJqvq/lHXImkwvmUgSZK8QiBJkrxCIEmSMBBIkiQMBJIkCQOBJEnCQCBJkjAQSJIk4P8DVlaDg43oM08AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbsX6cXhawJs"
      },
      "source": [
        "def read_data(file_path):\n",
        "    # trainx is a 463715 × 90 matrix of training data, where each row is a 90-dimensional feature representation of a song.\n",
        "    # trainy is a 463715 × 1 vector of labels associated with each training data. Each row is the release year of the corresponding song in trainx.\n",
        "    # testx is a 51630 × 90 matrix of test data.\n",
        "    \n",
        "    mat = scipy.io.loadmat(file_path)\n",
        "    train_x_data = mat['trainx']  # variable in mat file\n",
        "    train_x_columns = [f'col_{num}' for num in range(len(train_x_data[0]))]\n",
        "    train_x_rows = [f'index_{num}' for num in range(len(train_x_data))]\n",
        "    train_x_df = pd.DataFrame(train_x_data, columns=train_x_columns, index=train_x_rows)\n",
        "    train_y_data = mat['trainy']\n",
        "    y_column = ['year']\n",
        "    train_y_index = [f'index_{num}' for num in range(len(train_y_data))]\n",
        "    train_y_df = pd.DataFrame(train_y_data, columns=y_column, index=train_y_index)\n",
        "    test_x_data = mat['testx']  # variable in mat file\n",
        "    test_x_columns = [f'col_{num}' for num in range(len(test_x_data[0]))]\n",
        "    test_x_rows = [f'index_{num}' for num in range(len(test_x_data))]\n",
        "    test_x_df = pd.DataFrame(test_x_data, columns=test_x_columns, index=test_x_rows)\n",
        "    return train_x_df, train_y_df, test_x_df\n",
        "\n",
        "\n",
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.ylim([0, 10])\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Error [Year]')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhaomLSHcmyL"
      },
      "source": [
        "full_file_path = \"/content/MSdata.mat\"\n",
        "train_x_df, train_y_df, test_x_df = read_data(full_file_path)\n",
        "dataset = train_x_df.copy()\n",
        "# dataset.tail()\n",
        "# dataset.isna().sum()\n",
        "max_year = train_y_df['year'].max()\n",
        "min_year = train_y_df['year'].min()\n",
        "y_input = train_y_df.year\n",
        "x_train_split, x_test_split, y_train_split, y_test_split = train_test_split(train_x_df, y_input, test_size=0.1, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2aKGrz_xn-2"
      },
      "source": [
        "# columns = ['col_' + str(i) for i in range(90)]\n",
        "# print(columns)\n",
        "# sns.pairplot(train_x_df[columns], diag_kind='kde')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKSDC7Cxnw2v"
      },
      "source": [
        "# sns.pairplot(train_x_df[['col_' + str(i) for i in range(90)]], diag_kind='kde')\n",
        "# train_x_df.describe().transpose()\n",
        "# x_train_split.describe().transpose()[['mean', 'std']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5CyelnaFrop"
      },
      "source": [
        "train_features = x_train_split.copy()\n",
        "test_features = x_test_split.copy()\n",
        "train_labels = y_train_split.copy()\n",
        "test_labels = y_test_split.copy()\n",
        "\n",
        "\n",
        "preprocessingNormalizer = preprocessing.Normalization()\n",
        "preprocessingNormalizer.adapt(np.array(train_features))\n",
        "\n",
        "batchNormalizer = layers.BatchNormalization()\n",
        "\n",
        "def get_optimizer():\n",
        "  return tf.keras.optimizers.Adam(lr_schedule)\n",
        "\n",
        "\n",
        "def compile_and_fit(model, name, optimizer=None, max_epochs=10000):\n",
        "  if optimizer is None:\n",
        "    optimizer = get_optimizer()\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=tf.keras.losses.MeanAbsoluteError(),\n",
        "                metrics=[\n",
        "                  tf.keras.losses.MeanAbsoluteError(),\n",
        "                  'accuracy'])\n",
        "\n",
        "  model.summary()\n",
        "  checkpoint_filepath = '/tmp/checkpoint'\n",
        "  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "  \n",
        "  history = model.fit(\n",
        "    train_features, train_labels,\n",
        "    validation_split=0.2,\n",
        "    steps_per_epoch = STEPS_PER_EPOCH,\n",
        "    epochs=max_epochs,\n",
        "    callbacks=get_callbacks(name),\n",
        "    verbose=1)\n",
        "  return history\n",
        "\n",
        "FEATURES = 90\n",
        "dnn_model = tf.keras.Sequential([\n",
        "    preprocessingNormalizer,\n",
        "    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n",
        "                 activation='relu', input_shape=(FEATURES,)),\n",
        "    batchNormalizer,\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n",
        "                 activation='relu'),\n",
        "    #layers.Dropout(0.5),\n",
        "    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n",
        "                 activation='relu'),\n",
        "    #layers.Dropout(0.5),\n",
        "    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n",
        "                 activation='relu'),\n",
        "    #layers.Dropout(0.5),\n",
        "    layers.Dense(1)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db4UEuOC3Aoc",
        "outputId": "ec7446fb-791a-4d97-f8a1-5189261f0285"
      },
      "source": [
        "%%time\n",
        "history = compile_and_fit(dnn_model, \"dnn_model\", optimizer=None, max_epochs=10000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "normalization (Normalization (None, 90)                181       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               46592     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 837,302\n",
            "Trainable params: 836,097\n",
            "Non-trainable params: 1,205\n",
            "_________________________________________________________________\n",
            "Epoch 1/10000\n",
            "    3/10000 [..............................] - ETA: 26:44 - loss: 1997.6387 - mean_absolute_error: 1997.4693 - accuracy: 0.0000e+00WARNING:tensorflow:Callback method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0053s vs `on_train_batch_begin` time: 0.0209s). Check your callbacks.\n",
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0053s vs `on_train_batch_end` time: 0.0311s). Check your callbacks.\n",
            "10000/10000 [==============================] - 56s 5ms/step - loss: 137.4925 - mean_absolute_error: 137.2791 - accuracy: 0.0000e+00 - val_loss: 67.9774 - val_mean_absolute_error: 67.6930 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch: 0, accuracy:0.0000,  loss:91.7022,  mean_absolute_error:91.4643,  val_accuracy:0.0000,  val_loss:67.9774,  val_mean_absolute_error:67.6930,  \n",
            ".Epoch 2/10000\n",
            "10000/10000 [==============================] - 54s 5ms/step - loss: 52.9730 - mean_absolute_error: 52.6805 - accuracy: 0.0000e+00 - val_loss: 17.0133 - val_mean_absolute_error: 16.7002 - val_accuracy: 0.0000e+00\n",
            ".Epoch 3/10000\n",
            "10000/10000 [==============================] - 54s 5ms/step - loss: 21.1075 - mean_absolute_error: 20.7961 - accuracy: 0.0000e+00 - val_loss: 12.2507 - val_mean_absolute_error: 11.9533 - val_accuracy: 0.0000e+00\n",
            ".Epoch 4/10000\n",
            "10000/10000 [==============================] - 55s 5ms/step - loss: 9.9702 - mean_absolute_error: 9.6807 - accuracy: 0.0000e+00 - val_loss: 8.3104 - val_mean_absolute_error: 8.0513 - val_accuracy: 0.0000e+00\n",
            ".Epoch 5/10000\n",
            "10000/10000 [==============================] - 54s 5ms/step - loss: 9.0645 - mean_absolute_error: 8.8234 - accuracy: 0.0000e+00 - val_loss: 12.3860 - val_mean_absolute_error: 12.1922 - val_accuracy: 0.0000e+00\n",
            ".Epoch 6/10000\n",
            "10000/10000 [==============================] - 54s 5ms/step - loss: 8.7497 - mean_absolute_error: 8.5689 - accuracy: 0.0000e+00 - val_loss: 11.3194 - val_mean_absolute_error: 11.1655 - val_accuracy: 0.0000e+00\n",
            ".Epoch 7/10000\n",
            "10000/10000 [==============================] - 55s 5ms/step - loss: 8.4663 - mean_absolute_error: 8.3174 - accuracy: 0.0000e+00 - val_loss: 6.7302 - val_mean_absolute_error: 6.5910 - val_accuracy: 0.0000e+00\n",
            ".Epoch 8/10000\n",
            "10000/10000 [==============================] - 55s 6ms/step - loss: 8.3849 - mean_absolute_error: 8.2491 - accuracy: 0.0000e+00 - val_loss: 6.1115 - val_mean_absolute_error: 5.9810 - val_accuracy: 0.0000e+00\n",
            ".Epoch 9/10000\n",
            "10000/10000 [==============================] - 55s 5ms/step - loss: 8.0835 - mean_absolute_error: 7.9545 - accuracy: 0.0000e+00 - val_loss: 7.7154 - val_mean_absolute_error: 7.5897 - val_accuracy: 0.0000e+00\n",
            ".Epoch 10/10000\n",
            "10000/10000 [==============================] - 53s 5ms/step - loss: 8.0756 - mean_absolute_error: 7.9510 - accuracy: 0.0000e+00 - val_loss: 6.1549 - val_mean_absolute_error: 6.0318 - val_accuracy: 0.0000e+00\n",
            ".Epoch 11/10000\n",
            "10000/10000 [==============================] - 54s 5ms/step - loss: 8.0935 - mean_absolute_error: 7.9712 - accuracy: 0.0000e+00 - val_loss: 11.9041 - val_mean_absolute_error: 11.7826 - val_accuracy: 0.0000e+00\n",
            ".Epoch 12/10000\n",
            "10000/10000 [==============================] - 54s 5ms/step - loss: 8.1265 - mean_absolute_error: 8.0059 - accuracy: 0.0000e+00 - val_loss: 6.5863 - val_mean_absolute_error: 6.4664 - val_accuracy: 0.0000e+00\n",
            ".Epoch 13/10000\n",
            "10000/10000 [==============================] - 54s 5ms/step - loss: 7.9191 - mean_absolute_error: 7.7997 - accuracy: 0.0000e+00 - val_loss: 6.1557 - val_mean_absolute_error: 6.0355 - val_accuracy: 0.0000e+00\n",
            ".Epoch 14/10000\n",
            "10000/10000 [==============================] - 54s 5ms/step - loss: 7.8077 - mean_absolute_error: 7.6886 - accuracy: 0.0000e+00 - val_loss: 6.9949 - val_mean_absolute_error: 6.8756 - val_accuracy: 0.0000e+00\n",
            ".Epoch 15/10000\n",
            "10000/10000 [==============================] - 54s 5ms/step - loss: 7.7525 - mean_absolute_error: 7.6341 - accuracy: 0.0000e+00 - val_loss: 6.6731 - val_mean_absolute_error: 6.5548 - val_accuracy: 0.0000e+00\n",
            ".Epoch 16/10000\n",
            "10000/10000 [==============================] - 54s 5ms/step - loss: 7.5717 - mean_absolute_error: 7.4533 - accuracy: 0.0000e+00 - val_loss: 6.1080 - val_mean_absolute_error: 5.9895 - val_accuracy: 0.0000e+00\n",
            ".Epoch 17/10000\n",
            "10000/10000 [==============================] - 54s 5ms/step - loss: 7.6092 - mean_absolute_error: 7.4911 - accuracy: 0.0000e+00 - val_loss: 6.0763 - val_mean_absolute_error: 5.9578 - val_accuracy: 0.0000e+00\n",
            ".Epoch 18/10000\n",
            " 3406/10000 [=========>....................] - ETA: 30s - loss: 7.7951 - mean_absolute_error: 7.6772 - accuracy: 0.0000e+00"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCRpBVyy1uPk"
      },
      "source": [
        "dnn_model.load_weights(\"/content/dnn_model\")\n",
        "# plot_loss(history)\n",
        "test_results = {}\n",
        "test_results['dnn_model'] = dnn_model.evaluate(test_features, test_labels, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7OYbYHF-Gjl"
      },
      "source": [
        "pd.DataFrame(test_results, index=['Mean absolute error [Year]']).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4uzWVkbNCpV"
      },
      "source": [
        "import scipy.io\n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, PowerTransformer, PolynomialFeatures\n",
        "from sklearn import linear_model\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "data_path = '/content/MSdata.mat'\n",
        "\n",
        "\n",
        "# load data matrices, concatenate the data points with their labels, and return as one matrix\n",
        "def read_data(file_path):\n",
        "    mat = scipy.io.loadmat(file_path)\n",
        "    X = mat['trainx']\n",
        "    Y = mat['trainy']\n",
        "    test = mat['testx']\n",
        "    return X, Y, test\n",
        "\n",
        "\n",
        "X, Y, test = read_data(data_path)\n",
        "max_year = max(Y)\n",
        "min_year = min(Y)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)\n",
        "Y_train = Y_train.ravel()\n",
        "Y_test = Y_test.ravel()\n",
        "Y = Y.ravel()\n",
        "\n",
        "# SGD Regressor\n",
        "# r = SGDRegressor(loss='epsilon_insensitive', epsilon=0.01, max_iter=10000, tol=1e-5, penalty='l1')\n",
        "\n",
        "# Linear Ridge\n",
        "# r = linear_model.Ridge(alpha=.5)\n",
        "\n",
        "# Linear Lasso\n",
        "# r = linear_model.Lasso(alpha=0.01)\n",
        "\n",
        "# Linear Lasso LARS\n",
        "# r = linear_model.LassoLars(alpha=.1)\n",
        "\n",
        "# Bayesian Ridge\n",
        "#r = linear_model.BayesianRidge()\n",
        "\n",
        "# Logistic\n",
        "# r = LogisticRegression(penalty='l2', random_state=42)\n",
        "\n",
        "# Polynomial Degree 2\n",
        "#r = PolynomialFeatures(degree=2)\n",
        "\n",
        "# KNN Regressor\n",
        "# r = KNeighborsRegressor(n_neighbors=2)\n",
        "\n",
        "# MLP Regressor\n",
        "\n",
        "r = MLPRegressor(random_state=1, max_iter=500)\n",
        "\n",
        "reg = make_pipeline(StandardScaler(), r)\n",
        "\n",
        "# for testing on the training data to determine MAE\n",
        "\n",
        "# reg.fit_transform(X_train, Y_train)\n",
        "reg.fit(X_train, Y_train)\n",
        "\n",
        "pred = reg.predict(X_test)\n",
        "\n",
        "pred[pred > max_year] = max_year\n",
        "pred[pred < min_year] = min_year\n",
        "\n",
        "\n",
        "MAE = mean_absolute_error(Y_test, pred)\n",
        "print(MAE)\n",
        "\n",
        "\n",
        "# print(\"Writing.......\")\n",
        "# file = open('result_stochasticgd.csv', 'w')\n",
        "# file.write(\"dataid,prediction\\n\")\n",
        "# for i in range(len(pred)):\n",
        "#     file.write(\"{}, {} \\n\".format(i + 1, pred[i]))\n",
        "# file.close()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}